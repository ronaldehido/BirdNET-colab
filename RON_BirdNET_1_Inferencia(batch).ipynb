{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ronaldehido/BirdNET-colab/blob/main/RON_BirdNET_1_Inferencia(batch).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbauFjxhejo2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwHjQq2rer5G"
      },
      "source": [
        "# **Ejecución Modelo Personalizado CNN en BirdNET Analyzer**\n",
        "versión 2.1 (20-02-2025)\n",
        "update (14/03/2025)\n",
        "\n",
        "### *Ron A. Fernández-Gómez - EPM SECIHTI*\n",
        "(puntuacion omitida)\n",
        "Este es un flujo de trabajo en Google Colab escrito en Python para ejecutar modelos personalizados basados en Redes Neuronales Convolucionales (CNNs) para detección y clasificación de vocalizaciones de fauna utilizando la herramienta BirdNET Analyzer para uso con Interfaz de línea de comando (CLI).\n",
        "Para mayores detalles sobre BirdNET Analyzer y usos del proyecto BirdNET consultar: https://github.com/kahst/BirdNET-Analyzer\n",
        "\n",
        "\n",
        "Aunque los modelos compatibles con BirdNET Analyzer se generan en Tensorflow, algunos están en formato .tflite que pueden tener algunas limitaciones para optimizar procesos de inferencias basados en el uso de paralelización en GPU, delegando los procesos a la CPU. Por lo tanto en este flujo buscaremos trabajar en un entorno de ejecución de colab con recursos disponibles en CPU. Se recomienda usar v2-8 TPU que cuenta con la virtualización de 96 procesadores CPU.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FeLB9iP0hTr0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3ipxEPLYhQTm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHEVI-gipDtL"
      },
      "source": [
        "# 1. INFERENCIA: Deteccion de vocalizaciones por lotes\n",
        "Esta etapa corresponde a la ejecución de un modelo CNN por lotes. Permite ejecutar el modelo en una carpeta que contenga varios archivos de audio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OwAcgq_lvoD"
      },
      "source": [
        "## Paqueterías y dependencias necesarias\n",
        "Estas dependencias facilitaran el funcionamiento del analizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tffhDQmjluDD"
      },
      "outputs": [],
      "source": [
        "!pip install ffmpeg\n",
        "!pip install librosa\n",
        "!pip install resampy\n",
        "!pip install tensorflow==2.15.0\n",
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZHxi4Tijev9"
      },
      "source": [
        "##*Conectar a Google Drive y definir rutas*\n",
        "Primero vincularemos Google Drive con lo que definirimos las rutas de acceso a los archivos de trabajo y de salida de resultados durante la sesión de trabajo. En el Drive tedremos los archivos a analizar y los modelos personalizados a ejecutar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KxbW_Wy0jeC8"
      },
      "outputs": [],
      "source": [
        "# Conectar con google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STNt9fy-fy-X"
      },
      "outputs": [],
      "source": [
        "#Para trabajar con varios archivos hay que definir\n",
        "#Rutas de entrada y salida\n",
        "audio_path = '/ruta/a/la/carpeta/de/archivos' #definir esta ruta\n",
        "output_folder = '/ruta/a/la/carpeta/donde/guardar/los/resultados' #definir esta ruta\n",
        "\n",
        "#Ruta al modelo personalizado\n",
        "my_model = '/ruta/al/modelo/personalizado.tflite' #definir esta ruta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbD9u8KbrQEP"
      },
      "source": [
        "## Clonar BirdNET Analyzer\n",
        "Clonamos el respositorio de BirdNET Analyzer en nuestro espacio de trabajo a partir de GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGsYI97CrPs0"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/kahst/BirdNET-Analyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hq-w-0QCCgj"
      },
      "outputs": [],
      "source": [
        "#Para trabajar con varios archivos hay que definir\n",
        "#Rutas de entrada y salida\n",
        "audio_path = '/content/drive/Shareddrives/SOUNDSCAPES SELVA MAYA P2/2024.10-11_Oct-Nov/QR-FCP__Dzula__R202---FLAC/Data' #definir esta ruta\n",
        "output_folder = '/content/drive/MyDrive/BirdNet_results/outputdzulaR202' #definir esta ruta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vs9jjg8R11Qh"
      },
      "outputs": [],
      "source": [
        "%cd BirdNET-Analyzer\n",
        "#%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8jUL9wRp6iCX"
      },
      "outputs": [],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "KR6RITWjGNe5"
      },
      "outputs": [],
      "source": [
        "#Hacemos una prueba rapida con example para verificar funcionamiento correcto\n",
        "!python -m birdnet_analyzer.analyze \\\n",
        "        --combine_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "aTA9oMTNSMtK"
      },
      "outputs": [],
      "source": [
        "# Procesar una carpeta con archivos y el modelo personalizado, en este caso cargamos el modelo de WildMon dando la ruta del archivo\n",
        "!python -m birdnet_analyzer.analyze \\\n",
        "        --i \"{audio_path}\" \\\n",
        "        --o \"{output_folder}\" \\\n",
        "        --classifier \"{my_model}\" \\\n",
        "        --min_conf 0.5 \\ #definimos el minimo de confianza\n",
        "        --threads 96 \\ #denifimos la cantidad de hilos de procesadores CPU a utilizar, por ejmplo 96 el maximo del entorno de ejecución\n",
        "        --batchsize 32 \\ #definimos la cantidad de archivos a anlizar al tiempo.\n",
        "        --combine_results #solo se declara si se quiere unificar resultados en un archivo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto obtendremos un listado cvs con todas las detecciones"
      ],
      "metadata": {
        "id": "Bx1KIWMV-mww"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMtCcGLdu3i0CTzSQoa8mls",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}