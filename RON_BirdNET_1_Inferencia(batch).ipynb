{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BbauFjxhejo2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwHjQq2rer5G"
      },
      "source": [
        "# **Ejecución Modelo Personalizado CNN en BirdNET Analyzer**\n",
        "versión 2.1 (20-02-2025)\n",
        "\n",
        "### *Ron A. Fernández-Gómez - EPM SECIHTI*\n",
        "(puntuacion omitida)\n",
        "Este es un flujo de trabajo en Google Colab escrito en Python para ejecutar modelos personalizados basados en Redes Neuronales Convolucionales (CNNs) para detección y clasificación de vocalizaciones de fauna utilizando la herramienta BirdNET Analyzer para uso con Interfaz de línea de comando (CLI).\n",
        "Para mayores detalles sobre BirdNET Analyzer y usos del proyecto BirdNET consultar: https://github.com/kahst/BirdNET-Analyzer\n",
        "\n",
        "\n",
        "Aunque los modelos compatibles con BirdNET Analyzer se generan en Tensorflow, algunos están en formato .tflite que pueden tener algunas limitaciones para optimizar procesos de inferencias basados en el uso de paralelización en GPU, delegando los procesos a la CPU. Por lo tanto en este flujo buscaremos trabajar en un entorno de ejecución de colab con recursos disponibles en CPU. Se recomienda usar v2-8 TPU que cuenta con la virtualización de 96 procesadores CPU.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uHEVI-gipDtL"
      },
      "source": [
        "# 1. INFERENCIA: Deteccion de vocalizaciones por lotes\n",
        "Esta etapa corresponde a la ejecución de un modelo CNN por lotes. Permite ejecutar el modelo en una carpeta que contenga varios archivos de audio."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1OwAcgq_lvoD"
      },
      "source": [
        "## Paqueterías y dependencias necesarias\n",
        "Estas dependencias facilitaran el funcionamiento del analizador"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tffhDQmjluDD"
      },
      "outputs": [],
      "source": [
        "!pip install ffmpeg\n",
        "!pip install librosa\n",
        "!pip install resampy\n",
        "!pip install tensorflow==2.15.0\n",
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZHxi4Tijev9"
      },
      "source": [
        "##*Conectar a Google Drive y definir rutas*\n",
        "Primero vincularemos Google Drive con lo que definirimos las rutas de acceso a los archivos de trabajo y de salida de resultados durante la sesión de trabajo. En el Drive tedremos los archivos a analizar y los modelos personalizados a ejecutar."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KxbW_Wy0jeC8",
        "outputId": "e9731141-ba0f-4b9d-b3ea-1d854121cdfc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# Conectar con google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "STNt9fy-fy-X"
      },
      "outputs": [],
      "source": [
        "#Para trabajar con varios archivos hay que definir\n",
        "#Rutas de entrada y salida\n",
        "audio_path = '/ruta/a/la/carpeta/de/archivos' #definir esta ruta\n",
        "output_folder = '/ruta/a/la/carpeta/donde/guardar/los/resultados' #definir esta ruta\n",
        "\n",
        "#Ruta al modelo personalizado\n",
        "my_model = '/ruta/al/modelo/personalizado.tflite' #definir esta ruta"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbD9u8KbrQEP"
      },
      "source": [
        "## Clonar BirdNET Analyzer\n",
        "Clonamos el respositorio de BirdNET Analyzer en nuestro espacio de trabajo a partir de GitHub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oGsYI97CrPs0"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/kahst/BirdNET-Analyzer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9hq-w-0QCCgj"
      },
      "outputs": [],
      "source": [
        "#Para trabajar con varios archivos hay que definir\n",
        "#Rutas de entrada y salida\n",
        "audio_path = '/content/drive/Shareddrives/SOUNDSCAPES SELVA MAYA P2/2024.10-11_Oct-Nov/QR-FCP__Dzula__R202---FLAC/Data' #definir esta ruta\n",
        "output_folder = '/content/drive/MyDrive/BirdNet_results/outputdzulaR202' #definir esta ruta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vs9jjg8R11Qh",
        "outputId": "1f90f516-064d-4cfe-9f1b-55cdd7d6742c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/BirdNET-Analyzer\n"
          ]
        }
      ],
      "source": [
        "%cd BirdNET-Analyzer\n",
        "#%cd /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8jUL9wRp6iCX",
        "outputId": "1ddc3e06-ee48-4750-addb-12bf7ff78438"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/BirdNET-Analyzer\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "KR6RITWjGNe5",
        "outputId": "7396ff06-6cbc-41e2-ae7e-99fed0f287b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-02-03 04:46:42.596125: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1738558002.654282    5488 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1738558002.672810    5488 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2025-02-03 04:46:42.740232: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "Species list contains 6522 species\n",
            "Found 1 files to analyze\n",
            "Analyzing /content/BirdNET-Analyzer/birdnet_analyzer/example/soundscape.wav\n",
            "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
            "Finished /content/BirdNET-Analyzer/birdnet_analyzer/example/soundscape.wav in 5.01 seconds\n",
            "Combining results, writing to /content/BirdNET-Analyzer/birdnet_analyzer/example/...Error: Cannot combine results from /content/BirdNET-Analyzer/birdnet_analyzer/example/soundscape.BirdNET.selection.table.txt.\n",
            "\n",
            "done!\n"
          ]
        }
      ],
      "source": [
        "#Hacemos una prueba rapida con example para verificar funcionamiento correcto\n",
        "!python -m birdnet_analyzer.analyze \\\n",
        "        --combine_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "collapsed": true,
        "id": "aTA9oMTNSMtK"
      },
      "outputs": [],
      "source": [
        "# Procesar una carpeta con archivos y el modelo personalizado, en este caso cargamos el modelo de WildMon dando la ruta del archivo\n",
        "!python -m birdnet_analyzer.analyze \\\n",
        "        --i \"{audio_path}\" \\\n",
        "        --o \"{output_folder}\" \\\n",
        "        --classifier \"{my_model}\" \\\n",
        "        --min_conf 0.5 \\ #definimos el minimo de confianza\n",
        "        --threads 96 \\ #denifimos la cantidad de hilos de procesadores CPU a utilizar, por ejmplo 96 el maximo del entorno de ejecución\n",
        "        --batchsize 32 \\ #definimos la cantidad de archivos a anlizar al tiempo.\n",
        "        --combine_results #solo se declara si se quiere unificar resultados en un archivo\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con esto obtendremos un listado cvs con todas las detecciones"
      ],
      "metadata": {
        "id": "Bx1KIWMV-mww"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}